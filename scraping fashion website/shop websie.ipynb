{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Create a CSV file to write the data\n",
    "with open('products.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['Product Name', 'Product Price', 'Product Image URL', 'Product Description'])\n",
    "\n",
    "    # Loop through pages 1 to 3\n",
    "    for page_number in range(1, 4):\n",
    "        url = f\"https://www.susamusa.com/collections/shop-all?page={page_number}\"\n",
    "\n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content using BeautifulSoup\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            # Find all product items on the page\n",
    "            product_items = soup.find_all('div', class_='card--media')\n",
    "\n",
    "            for product in product_items:\n",
    "                # Extract product name\n",
    "                product_name = product.find('a', class_='full-unstyled-link').get_text(strip=True)\n",
    "\n",
    "                # Extract product price\n",
    "                product_price = product.find('span', class_='price-item--sale').get_text(strip=True)\n",
    "\n",
    "                # Extract product image URL\n",
    "                product_img = product.find('img', class_='lazyloaded')['data-src']\n",
    "\n",
    "                # Extract product description\n",
    "                product_url = \"https://www.susamusa.com\" + product.find('a', class_='full-unstyled-link')['href']\n",
    "                product_response = requests.get(product_url)\n",
    "                if product_response.status_code == 200:\n",
    "                    product_soup = BeautifulSoup(product_response.content, 'html.parser')\n",
    "                    product_description = product_soup.find('div', id='tab-1').get_text(strip=True)\n",
    "                else:\n",
    "                    product_description = \"Description not available\"\n",
    "\n",
    "                # Write the extracted information to the CSV file\n",
    "                csv_writer.writerow([product_name, product_price, product_img, product_description])\n",
    "\n",
    "        else:\n",
    "            print(f\"Failed to fetch page {page_number}\")\n",
    "\n",
    "print(\"Data has been saved to products.csv.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
