Certainly, here's a detailed explanation of each step in the provided code:

1. **File Opening and CSV Writer Initialization:**
   
   ```python
   with open('products.csv', 'w', newline='', encoding='utf-8') as csvfile:
       csv_writer = csv.writer(csvfile)
       csv_writer.writerow(['Product Name', 'Product Price', 'Product Image URL', 'Product Description'])
   ```
   
   - The code opens a CSV file named `products.csv` in write mode (`'w'`).
   - It specifies `'utf-8'` encoding to handle different characters properly.
   - It creates a `csv_writer` object to write data to the CSV file.
   - The first row containing column headers is written using `csv_writer.writerow()`.

2. **Looping Through Pages:**

   ```python
   for page_number in range(1, 4):
       url = f"https://www.susamusa.com/collections/shop-all?page={page_number}"
   ```

   - The loop iterates through page numbers from 1 to 3.
   - The `url` variable is constructed by inserting the page number into the URL template.

3. **Sending HTTP Requests and Parsing HTML:**

   ```python
   response = requests.get(url)
   if response.status_code == 200:
       soup = BeautifulSoup(response.content, 'html.parser')
   ```

   - An HTTP GET request is sent to the constructed URL using the `requests.get()` method.
   - The response status code is checked. If it's 200, the HTML content is parsed using `BeautifulSoup`.

4. **Finding Product Items:**

   ```python
   product_items = soup.find_all('div', class_='card--media')
   ```

   - The code finds all elements with the class `'card--media'`, which represent product items on the page.

5. **Extracting Product Information:**

   ```python
   for product in product_items:
       product_name = product.find('a', class_='full-unstyled-link').get_text(strip=True)
       product_price = product.find('span', class_='price-item--sale').get_text(strip=True)
       product_img = product.find('img', class_='lazyloaded')['data-src']
   ```

   - For each product item, the script extracts the product name, price, and image URL using the `find()` method and appropriate class names.

6. **Extracting Product Description:**

   ```python
   product_url = "https://www.susamusa.com" + product.find('a', class_='full-unstyled-link')['href']
   product_response = requests.get(product_url)
   if product_response.status_code == 200:
       product_soup = BeautifulSoup(product_response.content, 'html.parser')
       product_description = product_soup.find('div', id='tab-1').get_text(strip=True)
   else:
       product_description = "Description not available"
   ```

   - The URL of the product's individual page is constructed by combining the base URL and the relative URL obtained from the product element.
   - An HTTP GET request is sent to the individual product URL.
   - If the response status code is 200, the HTML content is parsed using `BeautifulSoup` and the product description is extracted.

7. **Writing Data to CSV:**

   ```python
   csv_writer.writerow([product_name, product_price, product_img, product_description])
   ```

   - The extracted product information is written to the CSV file using the `csv_writer.writerow()` method.

8. **Handling Errors:**

   ```python
   else:
       print(f"Failed to fetch page {page_number}")
   ```

   - If there's an issue fetching a page or product description, the script prints an error message.

9. **Completion Message:**

   ```python
   print("Data has been saved to products.csv.")
   ```

   - After processing all pages, the script prints a message indicating that the data has been saved to the CSV file.

Remember to install the required libraries (`requests`, `BeautifulSoup`, `csv`) before running the script, and ensure that you have permission to scrape the website you're targeting.
